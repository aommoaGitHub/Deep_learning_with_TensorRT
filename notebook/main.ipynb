{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Magma Keras to TensorRT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential,load_model, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.tensorrt as trt\n",
    "\n",
    "import time \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from os.path import isfile, exists, isdir, join\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Jetson TX2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "K.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_MODEL = 'MagmaCnnClassifier.hdf5'\n",
    "TARGET_SHAPE = 8\n",
    "DATA_SHAPE = (100,100,3)\n",
    "OPTIMIZER = Adam()\n",
    "BATCH_SIZE = 256\n",
    "EPOCH = 2\n",
    "\n",
    "SAVED_MODEL_DIR = './saved_model/'\n",
    "MODEL_NAME = CNN_MODEL\n",
    "\n",
    "DATA_SHAPE = (100,100,3)\n",
    "TRAIN_DIR = \"./data/train\"\n",
    "TEST_DIR = \"./data/test\"\n",
    "RESULT_PREDICTION_CALLBACK = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "### create predict_dir by move random pictures from test_dir  \n",
    "#### remove and copy test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove if exist test_dir success\n",
      "remove if exist predict_dir success\n",
      "copy test to test_dir success\n"
     ]
    }
   ],
   "source": [
    "TEST_COPY_DIR = './data/test_dir'\n",
    "PREDICT_DIR = './data/predict_dir'\n",
    "\n",
    "# delete folder if exist\n",
    "if exists(TEST_COPY_DIR) and isdir(TEST_COPY_DIR):\n",
    "    shutil.rmtree(TEST_COPY_DIR)\n",
    "print('remove if exist test_dir success')\n",
    "\n",
    "if exists(PREDICT_DIR) and isdir(PREDICT_DIR):\n",
    "    shutil.rmtree(PREDICT_DIR)\n",
    "print('remove if exist predict_dir success')\n",
    "\n",
    "#copy test as test_dir, there are result as list of copy files\n",
    "# from distutils.dir_util import copy_tree\n",
    "# copy_tree('./data/test','./data/test_dir')\n",
    "from subprocess import call\n",
    "call(['cp','-a', TEST_DIR, TEST_COPY_DIR])\n",
    "print('copy test to test_dir success')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create predict_dir and random moving images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy - category: 0 ['5760.png']\n",
      "copy - category: 1 ['2930.png']\n",
      "copy - category: 2 ['482.png']\n",
      "copy - category: 3 ['10205.png']\n",
      "copy - category: 4 ['3026.png']\n",
      "copy - category: 5 ['9067.png']\n",
      "copy - category: 6 ['6994.png']\n",
      "copy - category: 7 ['1708.png']\n"
     ]
    }
   ],
   "source": [
    "#random select images\n",
    "CATEGORIES = ['0','1','2','3','4','5','6','7']\n",
    "IMAGES_PER_FOLDER = 1\n",
    "\n",
    "import random\n",
    "for category in CATEGORIES:\n",
    "    \n",
    "    path_ct = join(TEST_COPY_DIR,category)\n",
    "    path_pd = join(PREDICT_DIR, category)\n",
    "    \n",
    "    if not exists(path_pd):\n",
    "        os.makedirs(path_pd)\n",
    "    \n",
    "    image_list = os.listdir(path_ct)\n",
    "    random.shuffle(image_list)\n",
    "    \n",
    "    for img in image_list[:IMAGES_PER_FOLDER]:\n",
    "        path_src = join(path_ct,img)\n",
    "        path_des = join(path_pd,img)\n",
    "        shutil.move(path_src, path_des)\n",
    "    \n",
    "    print('copy - category:',category, image_list[:IMAGES_PER_FOLDER])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WorkFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras to TensorRT\n",
    "![alt text](pictures/Keras_to_TensorRT.png)\n",
    "\n",
    "### Tensorflow to TensorRT\n",
    "![alt text](pictures/tf-trt_workflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a0. Convert Keras to Tensorflow model and a) Read input Tensorflow model\n",
    "##### don't need to read input Tensorflow because i don't save .mega tensorflow file from keras\n",
    "### Build Keras model (Declare + Train)\n",
    "#### a.1) Declare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_tensor (Conv2D)        (None, 98, 98, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 49, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 47, 47, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 21, 21, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "output_tensor (Dense)        (None, 8)                 4104      \n",
      "=================================================================\n",
      "Total params: 1,294,024\n",
      "Trainable params: 1,294,024\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    # Layer 1\n",
    "    Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=DATA_SHAPE, name='input_tensor'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Layer 2\n",
    "    Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Layer 3\n",
    "    Conv2D(filters=128, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Layer 4\n",
    "    Conv2D(filters=128, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    # flattening the model for fully connected layer\n",
    "    Flatten(),\n",
    "    Dropout(rate=0.5),\n",
    "    # fully connected layer\n",
    "    Dense(units=512, activation='relu'),\n",
    "    # output layer\n",
    "    Dense(units=TARGET_SHAPE, activation='softmax', name='output_tensor'),\n",
    "])\n",
    "\n",
    "# Compilile the network\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                    optimizer=OPTIMIZER,\n",
    "                    metrics=['categorical_accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a.2) create generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4917 images belonging to 8 classes.\n",
      "Found 1222 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1 / 255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1 / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory = TRAIN_DIR ,\n",
    "    target_size = DATA_SHAPE[:2],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    directory = TEST_COPY_DIR, # use test data that be splited for prediction\n",
    "    target_size = DATA_SHAPE[:2],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a.3) Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "19/19 [==============================] - 46s 2s/step - loss: 1.7804 - categorical_accuracy: 0.3367 - val_loss: 1.3234 - val_categorical_accuracy: 0.5654\n",
      "Epoch 2/2\n",
      "19/19 [==============================] - 37s 2s/step - loss: 1.2515 - categorical_accuracy: 0.5577 - val_loss: 0.8263 - val_categorical_accuracy: 0.7195\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3808cd68>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_dir = time.strftime(\"%Y_%m_%d-%H_%M_%S\", time.localtime())\n",
    "tb_cb = TensorBoard(log_dir='./logs/'+sub_dir,\n",
    "                    #histogram_freq=EPOCHS,\n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    write_grads=True,\n",
    "                    write_images=True,\n",
    "                    #update_freq='batch',\n",
    "                    )\n",
    "callbacks = [tb_cb]\n",
    "\n",
    "# train_generator, val_generator declare Data preprocessing\n",
    "\n",
    "model.fit_generator(generator=train_generator,\n",
    "                              steps_per_epoch=train_generator.n//BATCH_SIZE,\n",
    "                                epochs=EPOCH,\n",
    "                                validation_data=val_generator,\n",
    "                              validation_steps=val_generator.n//BATCH_SIZE,\n",
    "                                callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --save model .hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.save(SAVED_MODEL_DIR+CNN_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --load model .hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if isfile(SAVED_MODEL_DIR + MODEL_NAME):\n",
    "    model = load_model(filepath= SAVED_MODEL_DIR + MODEL_NAME)\n",
    "    model.summary()\n",
    "else:\n",
    "    raise Exception(\"--MODEL COULD NOT LOADED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras to TensorRT\n",
    "![alt text](pictures/Keras_to_TensorRT.png)\n",
    "## b) Convert to Frozen model .pb\n",
    "#### b.1) declare function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pb_filename = 'Magma_frozen_model.pb'\n",
    "\n",
    "def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\n",
    "    \"\"\"\n",
    "    Freezes the state of a session into a pruned computation graph.\n",
    "    Creates a new computation graph where variable nodes are replaced by\n",
    "    constants taking their current value in the session. The new graph will be\n",
    "    pruned so subgraphs that are not necessary to compute the requested\n",
    "    outputs are removed.\n",
    "    @param session The TensorFlow session to be frozen.\n",
    "    @param keep_var_names A list of variable names that should not be frozen,\n",
    "                          or None to freeze all the variables in the graph.\n",
    "    @param output_names Names of the relevant graph outputs.\n",
    "    @param clear_devices Remove the device directives from the graph for better portability.\n",
    "    @return The frozen graph definition.\n",
    "    \"\"\"\n",
    "    from tensorflow.python.framework.graph_util import convert_variables_to_constants\n",
    "    graph = session.graph\n",
    "    with graph.as_default():\n",
    "        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\n",
    "        output_names = output_names or []\n",
    "        output_names += [v.op.name for v in tf.global_variables()]\n",
    "        input_graph_def = graph.as_graph_def()\n",
    "        if clear_devices:\n",
    "            for node in input_graph_def.node:\n",
    "                node.device = \"\"\n",
    "        frozen_graph = convert_variables_to_constants(session, input_graph_def, output_names, freeze_var_names)\n",
    "        return frozen_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.2) Save the model to Protocol Buffers Format (.pb) as tf pb file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "# model is used here \n",
    "# K.set_session(tf.Session(graph=model.output.graph)) \n",
    "init = K.tf.global_variables_initializer() \n",
    "K.get_session().run(init)\n",
    "\n",
    "frozen_graph = freeze_session(K.get_session(), output_names=[out.op.name for out in model.outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frozen model is successfully stored!\n"
     ]
    }
   ],
   "source": [
    "#write the TensorRT model to be used later for inference\n",
    "with gfile.FastGFile(\"./saved_model/Magma_frozen_model.pb\", 'wb') as f:\n",
    "    f.write(frozen_graph.SerializeToString())\n",
    "print(\"Frozen model is successfully stored!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_tensor_input_1\n"
     ]
    }
   ],
   "source": [
    "for inp in model.inputs:\n",
    "    print(inp.op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_tensor_1/Softmax\n"
     ]
    }
   ],
   "source": [
    "for out in model.outputs:\n",
    "    print(out.op.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras to TensorRT\n",
    "![alt text](pictures/Keras_to_TensorRT.png)\n",
    "## c) Optimize the frozen model to TensorRT graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = [\"output_tensor_1/Softmax\"] # name of output layer\n",
    "\n",
    "# convert (optimize) frozen model to TensorRT model\n",
    "trt_graph = trt.create_inference_graph(\n",
    "    input_graph_def=frozen_graph,# frozen model\n",
    "    outputs=outputs,\n",
    "    max_batch_size=2,# specify your max batch size\n",
    "    max_workspace_size_bytes=2*(10**9),# specify the max workspace\n",
    "    precision_mode=\"FP32\") # precision, can be \"FP32\" (32 floating point precision) or \"FP16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the TensorRT model to be used later for inference\n",
    "with gfile.FastGFile(\"./saved_model/TensorRT_Magma_model.pb\", 'wb') as f:\n",
    "    f.write(trt_graph.SerializeToString())\n",
    "print(\"TensorRT model is successfully stored!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c.2) Count how many nodes/operations before and after optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many ops of the original frozen model\n",
    "all_nodes = len([1 for n in frozen_graph.node])\n",
    "print(\"numb. of all_nodes in frozen graph:\", all_nodes)\n",
    "\n",
    "# check how many ops that is converted to TensorRT engine\n",
    "trt_engine_nodes = len([1 for n in trt_graph.node if str(n.op) == 'TRTEngineOp'])\n",
    "print(\"numb. of trt_engine_nodes in TensorRT graph:\", trt_engine_nodes)\n",
    "all_nodes = len([1 for n in trt_graph.node])\n",
    "print(\"numb. of all_nodes in TensorRT graph:\", all_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c.3) Visualize the original and optimized graphs\n",
    "Using [netron](https://lutzroeder.github.io/netron/), the web application for vitsulaize model graph by upload .pb file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d) Inference using TensorRT model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d.1) Function to read \".pb\" model (TensorRT model is stored in \".pb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (can be used to read frozen model or TensorRT model)\n",
    "def read_pb_graph(model):\n",
    "    with gfile.FastGFile(model,'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    return graph_def"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prepare data for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for category in CATEGORIES:\n",
    "    path_pd = join(PREDICT_DIR, category)\n",
    "    class_num = CATEGORIES.index(category)\n",
    "    image_list = os.listdir(path_pd)\n",
    "    \n",
    "    for img in image_list:\n",
    "        images.append([join(path_pd,img),class_num,img])\n",
    "\n",
    "print(images)\n",
    "print(images[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLS = 5\n",
    "rows = len(images)//COLS+1\n",
    "\n",
    "input_img = []\n",
    "\n",
    "for idx, image in enumerate(images):\n",
    "    col = idx%COLS\n",
    "    row = idx//COLS\n",
    "    \n",
    "    img = load_img(path=image[0], color_mode='rgb', target_size=DATA_SHAPE)\n",
    "    #img = img_to_array(img)\n",
    "    img2predict = img.copy()\n",
    "    img2predict = img_to_array(img2predict)\n",
    "#     img2predict = np.expand_dims(img2predict,0)\n",
    "    img2predict /= 255\n",
    "    #int(img2predict)\n",
    "    print(img2predict.shape)\n",
    "    input_img.append(img2predict)\n",
    "    \n",
    "input_img = np.array(input_img)\n",
    "print(input_img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d.2) Perform inference using TensorRT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable\n",
    "TENSORRT_MODEL_PATH = './saved_model/TensorRT_Magma_model.pb'\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    with tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.50))) as sess:\n",
    "        # read TensorRT model\n",
    "        trt_graph = read_pb_graph(TENSORRT_MODEL_PATH)\n",
    "\n",
    "        # obtain the corresponding input-output tensor\n",
    "        tf.import_graph_def(trt_graph, name='')\n",
    "        input = sess.graph.get_tensor_by_name('input_tensor_input:0')\n",
    "        output = sess.graph.get_tensor_by_name('output_tensor_1/Softmax:0')\n",
    "\n",
    "        # in this case, it demonstrates to perform inference for 50 times\n",
    "        total_time = 0; n_time_inference = 50\n",
    "        out_pred = sess.run(output, feed_dict={input: input_img})\n",
    "        for i in range(n_time_inference):\n",
    "            t1 = time.time()\n",
    "            out_pred = sess.run(output, feed_dict={input: input_img})\n",
    "            t2 = time.time()\n",
    "            delta_time = t2 - t1\n",
    "            total_time += delta_time\n",
    "            print(\"needed time in inference-\" + str(i) + \": \", delta_time)\n",
    "        avg_time_tensorRT = total_time / n_time_inference\n",
    "        print(\"average inference time: \", avg_time_tensorRT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d.3) Perform inference using the original tensorflow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable\n",
    "FROZEN_MODEL_PATH = './saved_model/Magma_frozen_model.pb'\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    with tf.Session() as sess:\n",
    "        # read TensorRT model\n",
    "        frozen_graph = read_pb_graph(FROZEN_MODEL_PATH)\n",
    "\n",
    "        # obtain the corresponding input-output tensor\n",
    "        tf.import_graph_def(frozen_graph, name='')\n",
    "        input = sess.graph.get_tensor_by_name('conv2d_5_input:0')\n",
    "        output = sess.graph.get_tensor_by_name('output_tensor_1/Softmax:0')\n",
    "\n",
    "        # in this case, it demonstrates to perform inference for 50 times\n",
    "        total_time = 0; n_time_inference = 50\n",
    "        out_pred = sess.run(output, feed_dict={input: input_img})\n",
    "        for i in range(n_time_inference):\n",
    "            t1 = time.time()\n",
    "            out_pred = sess.run(output, feed_dict={input: input_img})\n",
    "            t2 = time.time()\n",
    "            delta_time = t2 - t1\n",
    "            total_time += delta_time\n",
    "            print(\"needed time in inference-\" + str(i) + \": \", delta_time)\n",
    "        avg_time_original_model = total_time / n_time_inference\n",
    "        print(\"average inference time: \", avg_time_original_model)\n",
    "        print(\"TensorRT improvement compared to the original model:\", avg_time_original_model/avg_time_tensorRT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d.4) Plot the prediction result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred in out_pred:\n",
    "#     plt.figure('img 1')\n",
    "    plt.imshow(img1, cmap='rgb')\n",
    "    plt.title('pred:' + str(np.argmax(pred)), fontsize=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Calulate Time, mAP, ACC of Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Process in TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate Time, mAP, ACC of converted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
