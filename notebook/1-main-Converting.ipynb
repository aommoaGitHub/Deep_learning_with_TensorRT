{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Magma Keras to TensorRT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential,load_model, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.tensorrt as trt\n",
    "\n",
    "import time \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from os.path import isfile, exists, isdir, join\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Jetson TX2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "K.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_MODEL = 'MagmaCnnClassifier.hdf5'\n",
    "TARGET_SHAPE = 8\n",
    "DATA_SHAPE = (100,100,3)\n",
    "OPTIMIZER = Adam()\n",
    "BATCH_SIZE = 256\n",
    "EPOCH = 2\n",
    "\n",
    "SAVED_MODEL_DIR = './saved_model/'\n",
    "MODEL_NAME = CNN_MODEL\n",
    "\n",
    "DATA_SHAPE = (100,100,3)\n",
    "TRAIN_DIR = \"./data/train\"\n",
    "TEST_DIR = \"./data/test\"\n",
    "RESULT_PREDICTION_CALLBACK = None\n",
    "\n",
    "sub_dir = time.strftime(\"%Y_%m_%d-%H_%M_%S\", time.localtime())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing\n",
    "### create predict_dir by move random pictures from test_dir  \n",
    "#### remove and copy test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove if exist test_dir success\n",
      "remove if exist predict_dir success\n",
      "copy test to test_dir success\n"
     ]
    }
   ],
   "source": [
    "TEST_COPY_DIR = './data/test_dir'\n",
    "PREDICT_DIR = './data/predict_dir'\n",
    "\n",
    "# delete folder if exist\n",
    "if exists(TEST_COPY_DIR) and isdir(TEST_COPY_DIR):\n",
    "    shutil.rmtree(TEST_COPY_DIR)\n",
    "print('remove if exist test_dir success')\n",
    "\n",
    "if exists(PREDICT_DIR) and isdir(PREDICT_DIR):\n",
    "    shutil.rmtree(PREDICT_DIR)\n",
    "print('remove if exist predict_dir success')\n",
    "\n",
    "#copy test as test_dir, there are result as list of copy files\n",
    "# from distutils.dir_util import copy_tree\n",
    "# copy_tree('./data/test','./data/test_dir')\n",
    "from subprocess import call\n",
    "call(['cp','-a', TEST_DIR, TEST_COPY_DIR])\n",
    "print('copy test to test_dir success')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create predict_dir and random moving images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy - category: 0 ['2506.png', '3641.png', '9631.png']\n",
      "copy - category: 1 ['7784.png', '2555.png', '1955.png']\n",
      "copy - category: 2 ['6655.png', '507.png', '1713.png']\n",
      "copy - category: 3 ['1017.png', '6354.png', '4301.png']\n",
      "copy - category: 4 ['510.png', '6733.png', '5105.png']\n",
      "copy - category: 5 ['6708.png', '4340.png', '8349.png']\n",
      "copy - category: 6 ['1421.png', '4295.png', '1443.png']\n",
      "copy - category: 7 ['10121.png', '6196.png', '3401.png']\n"
     ]
    }
   ],
   "source": [
    "#random select images\n",
    "CATEGORIES = ['0','1','2','3','4','5','6','7']\n",
    "IMAGES_PER_FOLDER = 3\n",
    "\n",
    "import random\n",
    "for category in CATEGORIES:\n",
    "    \n",
    "    path_ct = join(TEST_COPY_DIR,category)\n",
    "    path_pd = join(PREDICT_DIR, category)\n",
    "    \n",
    "    if not exists(path_pd):\n",
    "        os.makedirs(path_pd)\n",
    "    \n",
    "    image_list = os.listdir(path_ct)\n",
    "    random.shuffle(image_list)\n",
    "    \n",
    "    for img in image_list[:IMAGES_PER_FOLDER]:\n",
    "        path_src = join(path_ct,img)\n",
    "        path_des = join(path_pd,img)\n",
    "        shutil.move(path_src, path_des)\n",
    "    \n",
    "    print('copy - category:',category, image_list[:IMAGES_PER_FOLDER])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WorkFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras to TensorRT\n",
    "![alt text](pictures/Keras_to_TensorRT.png)\n",
    "\n",
    "### Tensorflow to TensorRT\n",
    "![alt text](pictures/tf-trt_workflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a0. Convert Keras to Tensorflow model and a) Read input Tensorflow model\n",
    "##### don't need to read input Tensorflow because i don't save .mega tensorflow file from keras\n",
    "### Build Keras model (Declare + Train)\n",
    "#### a.1) Declare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_tensor (Conv2D)        (None, 98, 98, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 49, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 47, 47, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 21, 21, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "output_tensor (Dense)        (None, 8)                 4104      \n",
      "=================================================================\n",
      "Total params: 1,294,024\n",
      "Trainable params: 1,294,024\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    # Layer 1\n",
    "    Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=DATA_SHAPE, name='input_tensor'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Layer 2\n",
    "    Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Layer 3\n",
    "    Conv2D(filters=128, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Layer 4\n",
    "    Conv2D(filters=128, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    # flattening the model for fully connected layer\n",
    "    Flatten(),\n",
    "    Dropout(rate=0.5),\n",
    "    # fully connected layer\n",
    "    Dense(units=512, activation='relu'),\n",
    "    # output layer\n",
    "    Dense(units=TARGET_SHAPE, activation='softmax', name='output_tensor'),\n",
    "])\n",
    "\n",
    "# Compilile the network\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                    optimizer=OPTIMIZER,\n",
    "                    metrics=['categorical_accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a.2) create generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4917 images belonging to 8 classes.\n",
      "Found 1206 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1 / 255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1 / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory = TRAIN_DIR ,\n",
    "    target_size = DATA_SHAPE[:2],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    directory = TEST_COPY_DIR, # use test data that be splited for prediction\n",
    "    target_size = DATA_SHAPE[:2],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a.3) Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "19/19 [==============================] - 49s 3s/step - loss: 1.7361 - categorical_accuracy: 0.3543 - val_loss: 1.2091 - val_categorical_accuracy: 0.5947\n",
      "Epoch 2/2\n",
      "19/19 [==============================] - 39s 2s/step - loss: 1.2123 - categorical_accuracy: 0.5681 - val_loss: 0.9306 - val_categorical_accuracy: 0.6674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4008bc18>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb_cb = TensorBoard(log_dir='./logs/'+sub_dir,\n",
    "                    #histogram_freq=EPOCHS,\n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    write_grads=True,\n",
    "                    write_images=True,\n",
    "                    #update_freq='batch',\n",
    "                    )\n",
    "callbacks = [tb_cb]\n",
    "\n",
    "# train_generator, val_generator declare Data preprocessing\n",
    "\n",
    "model.fit_generator(generator=train_generator,\n",
    "                              steps_per_epoch=train_generator.n//BATCH_SIZE,\n",
    "                                epochs=EPOCH,\n",
    "                                validation_data=val_generator,\n",
    "                              validation_steps=val_generator.n//BATCH_SIZE,\n",
    "                                callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --save model .hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.save(SAVED_MODEL_DIR+CNN_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --load model .hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K.get_session().reset()\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_tensor (Conv2D)        (None, 98, 98, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 49, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 47, 47, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 21, 21, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "output_tensor (Dense)        (None, 8)                 4104      \n",
      "=================================================================\n",
      "Total params: 1,294,024\n",
      "Trainable params: 1,294,024\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if isfile(SAVED_MODEL_DIR+MODEL_NAME):\n",
    "    model = load_model(filepath=SAVED_MODEL_DIR+MODEL_NAME)\n",
    "    model.summary()\n",
    "else:\n",
    "    raise Exception(\"--MODEL COULD NOT LOADED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras to TensorRT\n",
    "![alt text](pictures/Keras_to_TensorRT.png)\n",
    "## b) Convert to Frozen model .pb\n",
    "#### b.1) declare function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pb_filename = 'Magma_frozen_model.pb'\n",
    "\n",
    "def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\n",
    "    \"\"\"\n",
    "    Freezes the state of a session into a pruned computation graph.\n",
    "    Creates a new computation graph where variable nodes are replaced by\n",
    "    constants taking their current value in the session. The new graph will be\n",
    "    pruned so subgraphs that are not necessary to compute the requested\n",
    "    outputs are removed.\n",
    "    @param session The TensorFlow session to be frozen.\n",
    "    @param keep_var_names A list of variable names that should not be frozen,\n",
    "                          or None to freeze all the variables in the graph.\n",
    "    @param output_names Names of the relevant graph outputs.\n",
    "    @param clear_devices Remove the device directives from the graph for better portability.\n",
    "    @return The frozen graph definition.\n",
    "    \"\"\"\n",
    "    from tensorflow.python.framework.graph_util import convert_variables_to_constants\n",
    "    graph = session.graph\n",
    "    with graph.as_default():\n",
    "        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\n",
    "        output_names = output_names or []\n",
    "        output_names += [v.op.name for v in tf.global_variables()]\n",
    "        input_graph_def = graph.as_graph_def()\n",
    "        if clear_devices:\n",
    "            for node in input_graph_def.node:\n",
    "                node.device = \"\"\n",
    "        frozen_graph = convert_variables_to_constants(session, input_graph_def, output_names, freeze_var_names)\n",
    "        return frozen_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.2) Save the model to Protocol Buffers Format (.pb) as tf pb file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 53 variables.\n",
      "INFO:tensorflow:Converted 53 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "# model is used here \n",
    "# K.set_session(tf.Session(graph=model.output.graph)) \n",
    "# init = K.tf.global_variables_initializer() \n",
    "# K.get_session().run(init)\n",
    "\n",
    "frozen_graph = freeze_session(K.get_session(), output_names=[out.op.name for out in model.outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Magma_frozen_model-2019_07_08-15_30_13.pb is successfully stored!\n"
     ]
    }
   ],
   "source": [
    "#write the TensorRT model to be used later for inference\n",
    "pb_filename = \"Magma_frozen_model-\"+sub_dir+\".pb\"\n",
    "\n",
    "with gfile.FastGFile(SAVED_MODEL_DIR + pb_filename, 'wb') as f:\n",
    "    f.write(frozen_graph.SerializeToString())\n",
    "print(pb_filename + \" is successfully stored!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_tensor_input\n"
     ]
    }
   ],
   "source": [
    "for inp in model.inputs:\n",
    "    print(inp.op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_tensor/Softmax\n"
     ]
    }
   ],
   "source": [
    "for out in model.outputs:\n",
    "    print(out.op.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a PB File by Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.platform import gfile\n",
    "with tf.Session() as sess:\n",
    "    with gfile.FastGFile(name=SAVED_MODEL_DIR + pb_filename,mode='rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        sess.graph.as_default()\n",
    "        g_in = tf.import_graph_def(graph_def)\n",
    "    \n",
    "    writer = tf.summary.FileWriter('./saved_model/Magma_frozen_log/'+sub_dir)\n",
    "    writer.add_graph(sess.graph)\n",
    "    writer.flush()\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras to TensorRT\n",
    "![alt text](pictures/Keras_to_TensorRT.png)\n",
    "## c) Optimize the frozen model to TensorRT graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = [out.op.name for out in model.outputs] # name of output layer\n",
    "\n",
    "# convert (optimize) frozen model to TensorRT model\n",
    "trt_graph = trt.create_inference_graph(\n",
    "    input_graph_def=frozen_graph,# frozen model\n",
    "    outputs=outputs,\n",
    "    max_batch_size=BATCH_SIZE,# specify your max batch size\n",
    "    max_workspace_size_bytes=2*(10**9),# specify the max workspace\n",
    "    precision_mode=\"FP32\") # precision, can be \"FP32\" (32 floating point precision) or \"FP16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorRT_Magma_model-2019_07_08-15_30_13.pb is successfully stored!\n"
     ]
    }
   ],
   "source": [
    "#write the TensorRT model to be used later for inference\n",
    "pb_trt_filename = \"TensorRT_Magma_model-\"+sub_dir+\".pb\"\n",
    "\n",
    "with gfile.FastGFile(SAVED_MODEL_DIR + pb_trt_filename, 'wb') as f:\n",
    "    f.write(trt_graph.SerializeToString())\n",
    "print(pb_trt_filename + \" is successfully stored!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a TensorRT PB File by Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.platform import gfile\n",
    "with tf.Session() as sess:\n",
    "    with gfile.FastGFile(name=SAVED_MODEL_DIR+pb_trt_filename, mode='rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        sess.graph.as_default()\n",
    "        g_in = tf.import_graph_def(graph_def)\n",
    "    \n",
    "    writer = tf.summary.FileWriter('./saved_model/TensorRT_frozen_log/'+sub_dir)\n",
    "    writer.add_graph(sess.graph)\n",
    "    writer.flush()\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c.2) Count how many nodes/operations before and after optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numb. of all_nodes in frozen graph: 120\n",
      "numb. of trt_engine_nodes in TensorRT graph: 3\n",
      "numb. of all_nodes in TensorRT graph: 29\n"
     ]
    }
   ],
   "source": [
    "# check how many ops of the original frozen model\n",
    "all_nodes = len([1 for n in frozen_graph.node])\n",
    "print(\"numb. of all_nodes in frozen graph:\", all_nodes)\n",
    "\n",
    "# check how many ops that is converted to TensorRT engine\n",
    "trt_engine_nodes = len([1 for n in trt_graph.node if str(n.op) == 'TRTEngineOp'])\n",
    "print(\"numb. of trt_engine_nodes in TensorRT graph:\", trt_engine_nodes)\n",
    "all_nodes = len([1 for n in trt_graph.node])\n",
    "print(\"numb. of all_nodes in TensorRT graph:\", all_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c.3) Visualize the original and optimized graphs\n",
    "Using [netron](https://lutzroeder.github.io/netron/), the web application for vitsulaize model graph by upload .pb file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
